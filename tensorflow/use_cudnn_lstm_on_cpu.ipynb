{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_use_cudnn_lstm_on_cpu.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/muik/notebooks/blob/master/tensorflow/use_cudnn_lstm_on_cpu.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "vYkeqiIys77t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow CuDNN LSTM example\n",
        "\n",
        "Use Tensorflow CuDNN LSTM trained model on CPU by CudnnCompatibleLSTMCell"
      ]
    },
    {
      "metadata": {
        "id": "GCSSWeY4lVye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "9afc7f90-f476-42f3-d1f7-65d14a73d6ac"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.contrib.rnn.python.ops import rnn as contrib_rnn\n",
        "from tensorflow.contrib.cudnn_rnn.python.layers import cudnn_rnn\n",
        "from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n",
        "from tensorflow.python.ops import rnn_cell\n",
        "\n",
        "MODEL_SAVE_PATH = './model'\n",
        "\n",
        "num_layers = 2 # rnn layers\n",
        "num_dirs = 2 # bidirectional\n",
        "num_units = 3 # rnn hidden\n",
        "batch_size = 5\n",
        "time_len = 12\n",
        "input_size = 4 # input dim\n",
        "\n",
        "def build_graph(is_training=False):\n",
        "  lstm = cudnn_rnn.CudnnLSTM(num_layers=num_layers, num_units=num_units,\n",
        "                             direction=cudnn_rnn_ops.CUDNN_RNN_BIDIRECTION)\n",
        "  inputs = tf.random_uniform((batch_size, time_len, input_size), seed=1)\n",
        "  inputs = tf.transpose(inputs, [1, 0, 2]) # [time_len, batch_size, input_size]\n",
        "  \n",
        "  initial_state = tf.random_uniform((batch_size, num_units), seed=2)\n",
        "  initial_state = tf.expand_dims(initial_state, 0)\n",
        "  c = tf.concat([initial_state for _ in range(num_layers*num_dirs)], 0)\n",
        "  h = tf.zeros([num_layers * num_dirs, batch_size, num_units])\n",
        "  initial_state = (h, c)\n",
        "  \n",
        "  outputs, (output_h, output_c) = lstm(inputs, initial_state=initial_state,\n",
        "                                       training=is_training)\n",
        "  \n",
        "  # [time_len, batch_size, num_dirs * num_units] > [batch_size, time_len, num_dirs * num_units]\n",
        "  outputs = tf.transpose(outputs, [1, 0, 2])\n",
        "  \n",
        "  last_h_state = tf.concat([output_h[-2], output_h[-1]], 1)\n",
        "  last_c_state = tf.concat([output_c[-2], output_c[-1]], 1)\n",
        "  return outputs, last_c_state, last_h_state\n",
        "\n",
        "def build_compat_graph():\n",
        "  base_cell = tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell\n",
        "  single_cell = lambda: base_cell(num_units)\n",
        "  cells_fw = [single_cell() for _ in range(num_layers)]\n",
        "  cells_bw = [single_cell() for _ in range(num_layers)]\n",
        "  inputs = tf.random_uniform((batch_size, time_len, input_size), seed=1)\n",
        "  \n",
        "  initial_state = tf.random_uniform((batch_size, num_units), seed=2)\n",
        "  c = initial_state\n",
        "  h = tf.zeros([batch_size, num_units])\n",
        "  state_tuple = rnn_cell.LSTMStateTuple(c, h)\n",
        "  initial_states_fw = initial_states_bw = [state_tuple] * num_layers\n",
        "  \n",
        "  (outputs, output_state_fw,\n",
        "   output_state_bw) = contrib_rnn.stack_bidirectional_dynamic_rnn(\n",
        "      cells_fw, cells_bw, inputs, dtype=tf.float32,\n",
        "      initial_states_fw=initial_states_fw, initial_states_bw=initial_states_bw,\n",
        "      time_major=False, scope='cudnn_lstm/stack_bidirectional_rnn')\n",
        "  last_h_state = tf.concat([output_state_fw[-1].h, output_state_bw[-1].h], 1)\n",
        "  last_c_state = tf.concat([output_state_fw[-1].c, output_state_bw[-1].c], 1)\n",
        "  return outputs, last_c_state, last_h_state\n",
        "\n",
        "# Cudnn training\n",
        "with tf.Graph().as_default() as graph:\n",
        "  ops = build_graph(is_training=True)\n",
        "  saver = tf.train.Saver()\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    outputs, c_state, h_state = sess.run(ops)\n",
        "    print(outputs[0][0], c_state[0], h_state[0])\n",
        "    saver.save(sess, MODEL_SAVE_PATH)\n",
        "\n",
        "# Cudnn restore & inference\n",
        "with tf.Graph().as_default() as graph:\n",
        "  ops = build_graph(is_training=False)\n",
        "  saver = tf.train.Saver()\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver.restore(sess, MODEL_SAVE_PATH)\n",
        "    outputs, c_state, h_state = sess.run(ops)\n",
        "    print(outputs[0][0], c_state[0], h_state[0])\n",
        "\n",
        "# CudnnCompatible restore & inference\n",
        "with tf.Graph().as_default() as graph:\n",
        "  ops = build_compat_graph()\n",
        "  saver = tf.train.Saver()\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver.restore(sess, MODEL_SAVE_PATH)\n",
        "    outputs, c_state, h_state = sess.run(ops)\n",
        "    print(outputs[0][0], c_state[0], h_state[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0\n",
            "(array([ 0.16085729,  0.12783323,  0.07822829, -0.00185133, -0.05733256,\n",
            "       -0.04276047], dtype=float32), array([-0.0851168 ,  0.12208229,  0.00152305, -0.00415992, -0.12166481,\n",
            "       -0.08929548], dtype=float32), array([-0.04304137,  0.0662911 ,  0.00084107, -0.00185133, -0.05733256,\n",
            "       -0.04276047], dtype=float32))\n",
            "INFO:tensorflow:Restoring parameters from ./model\n",
            "(array([ 0.16085729,  0.12783323,  0.07822829, -0.00185133, -0.05733256,\n",
            "       -0.04276047], dtype=float32), array([-0.0851168 ,  0.12208229,  0.00152305, -0.00415992, -0.12166481,\n",
            "       -0.08929548], dtype=float32), array([-0.04304137,  0.0662911 ,  0.00084107, -0.00185133, -0.05733256,\n",
            "       -0.04276047], dtype=float32))\n",
            "INFO:tensorflow:Restoring parameters from ./model\n",
            "(array([ 0.16085729,  0.12783323,  0.07822829, -0.00185133, -0.05733256,\n",
            "       -0.04276047], dtype=float32), array([-0.0851168 ,  0.12208231,  0.00152306, -0.00415991, -0.12166481,\n",
            "       -0.08929548], dtype=float32), array([-0.04304137,  0.06629111,  0.00084108, -0.00185133, -0.05733256,\n",
            "       -0.04276047], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}