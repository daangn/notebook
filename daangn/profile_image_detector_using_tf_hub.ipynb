{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "daangn_profile_image_detector_using_tf_hub.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/muik/notebooks/blob/master/daangn/profile_image_detector_using_tf_hub.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "G3uSli-pfJFX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 당근이 이미지 탐지기\n",
        "당근마켓의 당근이 캐릭터 이미지 탐지기 구현/배포 코드입니다."
      ]
    },
    {
      "metadata": {
        "id": "QixRwcSWqiUI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Model\n",
        "\n",
        "스텝별 코드의 설명은 다음의 블로그 글을 참고해주세요.\n",
        "\n",
        "https://medium.com/p/abd967638c8e/edit"
      ]
    },
    {
      "metadata": {
        "id": "0UOyaCJN4ii7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1~4) Build Tensorflow graph\n"
      ]
    },
    {
      "metadata": {
        "id": "7wa4-e9IwolO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip -q install tensorflow-hub\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "CHANNELS = 3 # number of image channels (RGB)\n",
        "\n",
        "def build_graph(hub_module_url, target_image_path):\n",
        "  # Step 1) Prepare pre-trained model for extracting image features.\n",
        "  module = hub.Module(hub_module_url)\n",
        "  height, width = hub.get_expected_image_size(module)\n",
        "\n",
        "  # Copied a method of https://github.com/GoogleCloudPlatform/cloudml-samples/blob/bf0680726/flowers/trainer/model.py#L181\n",
        "  # and fixed for all type images (not only jpeg)\n",
        "  def decode_and_resize(image_str_tensor):\n",
        "    \"\"\"Decodes jpeg string, resizes it and returns a uint8 tensor.\"\"\"\n",
        "    image = tf.image.decode_image(image_str_tensor, channels=CHANNELS)\n",
        "    # Note resize expects a batch_size, but tf_map supresses that index,\n",
        "    # thus we have to expand then squeeze.  Resize returns float32 in the\n",
        "    # range [0, uint8_max]\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    image = tf.image.resize_bilinear(\n",
        "        image, [height, width], align_corners=False)\n",
        "    image = tf.squeeze(image, squeeze_dims=[0])\n",
        "    image = tf.cast(image, dtype=tf.uint8)\n",
        "    return image\n",
        "\n",
        "  def to_img_feature(images):\n",
        "    \"\"\"Extract the feature of image vectors\"\"\"\n",
        "    outputs = module(dict(images=images), signature=\"image_feature_vector\", as_dict=True)\n",
        "    return outputs['default']\n",
        "\n",
        "  # Step 2) Extract image features of the target image.\n",
        "  target_image_bytes = tf.gfile.GFile(target_image_path, 'rb').read()\n",
        "  target_image = tf.constant(target_image_bytes, dtype=tf.string)\n",
        "  target_image = decode_and_resize(target_image)\n",
        "  target_image = tf.image.convert_image_dtype(target_image, dtype=tf.float32)\n",
        "  target_image = tf.expand_dims(target_image, 0)\n",
        "  target_image = to_img_feature(target_image)\n",
        "\n",
        "  # Step 3) Extract image features of input images.\n",
        "  input_byte = tf.placeholder(tf.string, shape=[None])\n",
        "  input_image = tf.map_fn(decode_and_resize, input_byte, back_prop=False, dtype=tf.uint8)\n",
        "  input_image = tf.image.convert_image_dtype(input_image, dtype=tf.float32)\n",
        "  input_image = to_img_feature(input_image)\n",
        "\n",
        "  # Step 4) Compare cosine_similarities of the target image and the input images.\n",
        "  dot = tf.tensordot(target_image, tf.transpose(input_image), 1)\n",
        "  similarity = dot / (tf.norm(target_image, axis=1) * tf.norm(input_image, axis=1))\n",
        "  similarity = tf.reshape(similarity, [-1])\n",
        "  \n",
        "  return input_byte, similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7rmvlfTZqzDX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5) Run"
      ]
    },
    {
      "metadata": {
        "id": "nfONhGSbe-38",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Download target and input images"
      ]
    },
    {
      "metadata": {
        "id": "DDgKbGghq0_1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_image_url = \"https://d2192bm55jmxp1.cloudfront.net/resize/s/profile/201712/B4CFF0B690BB910AF5CB97A2122E9AEC427DAD810E4E0382B13643C9A8D22A55.jpg\" #@param {type:\"string\"}\n",
        "input_image1_url = \"https://d2192bm55jmxp1.cloudfront.net/resize/s/profile/201706/5b193314eff5f5b90faf9e5600d2c95c0c86c4c154414ea8a69bc26942a37613.jpg\" #@param {type:\"string\"}\n",
        "input_image2_url = \"https://d2192bm55jmxp1.cloudfront.net/resize/s/profile/201803/b15cd493adfd367b6663786ca21c4ecdeba67c859ac628849ebd4c3f7990f92b.jpg\" #@param {type:\"string\"}\n",
        "input_image3_url = \"https://d2192bm55jmxp1.cloudfront.net/resize/s/profile/201804/8d4b782228f43fb859076c41ae69a1920aec1b20154ea059a8e87142b66a9841.jpg\" #@param {type:\"string\"}\n",
        "input_image4_url = \"https://d2192bm55jmxp1.cloudfront.net/resize/s/profile/201803/4D2C44F3BB10CB84D0D6894321ED9C8761BB364786550762DC13B125B4C34361.jpg\" #@param {type:\"string\"}\n",
        "\n",
        "input_image_urls = [input_image1_url, input_image2_url, input_image3_url, input_image4_url]\n",
        "\n",
        "target_img_path = 'target_img.jpg'\n",
        "input_img_paths = []\n",
        "\n",
        "!wget -q {target_image_url} -O {target_img_path}\n",
        "\n",
        "for i, url in enumerate(input_image_urls):\n",
        "  if len(url) > 0:\n",
        "    path = \"input_img%d.jpg\" % i\n",
        "    !wget -q {url} -O {path}\n",
        "    input_img_paths.append(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iykS13hfKnx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Compare  target and input images\n",
        "\n",
        "**hub_module_url** 필드값은 이미지 모듈의 url 입니다.\n",
        "\n",
        "이미지 사이즈와 성능/속도에 따라 다양한 모듈이 있습니다. TF Hub의 [Image Modules](https://www.tensorflow.org/hub/modules/image) 를 참고해주세요.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CKXcZN1KkysM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "bf01b341-7caa-440e-d469-03c78bc12447"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from IPython.display import Image, display\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# Load bytes of image files\n",
        "image_bytes = [tf.gfile.GFile(name, 'rb').read()\n",
        "               for name in [target_img_path] + input_img_paths]\n",
        "\n",
        "hub_module_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_96/feature_vector/1\" #@param {type:\"string\"}\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  input_byte, similarity_op = build_graph(hub_module_url, target_img_path)\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    t0 = time.time() # for time check\n",
        "    \n",
        "    # Inference similarities\n",
        "    similarities = sess.run(similarity_op, feed_dict={input_byte: image_bytes})\n",
        "    \n",
        "    print(\"%d images inference time: %.2f s\" % (len(similarities), time.time() - t0))\n",
        "\n",
        "# Display results\n",
        "print(\"# Target image\")\n",
        "display(Image(target_img_path))\n",
        "print(\"- similarity: %.2f\" % similarities[0])\n",
        "\n",
        "print(\"# Input images\")\n",
        "for similarity, input_img_path in zip(similarities[1:], input_img_paths):\n",
        "  display(Image(input_img_path))\n",
        "  print(\"- similarity: %.2f\" % similarity)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 images inference time: 1.67 s\n",
            "# Target image\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAYEBAUEBAYFBQUGBgYHCQ4JCQgICRINDQoOFRIWFhUS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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "- similarity: 1.00\n",
            "# Input images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAYEBAUEBAYFBQUGBgYHCQ4JCQgICRINDQoOFRIWFhUS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\nCUFT+CMBS/pLACSlXUJf/ioOFOUWaeO/Z//Z\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "- similarity: 0.26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAYEBAUEBAYFBQUGBgYHCQ4JCQgICRINDQoOFRIWFhUS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\nloRRRRRqhf/Z\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "- similarity: 0.71\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAYEBAUEBAYFBQUGBgYHCQ4JCQgICRINDQoOFRIWFhUS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\n0OWEgZwBsPQf2rZbe0FWBnPtvWBA0JTj5SBtXpazkdMHypFiSdMMB4yf/9k=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "- similarity: 0.36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAYEBAUEBAYFBQUGBgYHCQ4JCQgICRINDQoOFRIWFhUS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\nbT/EKlTHkDiAtobi6v1ebaIDKD396e0Kq3IgbyFXAnSRgKuOlbKzOM//2Q==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "- similarity: 0.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ssqWGt8W33oT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Deploy on Cloud ML Engine\n",
        "위의 텐서플로우 모델을 클라우드 머신러닝 엔진에 배포합니다."
      ]
    },
    {
      "metadata": {
        "id": "wWWzV1NH4GvK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Export the tensorflow model file\n",
        "모델을 배포하기 위한 텐서플로우 모델을 파일로 저장합니다.\n"
      ]
    },
    {
      "metadata": {
        "id": "VC9fRXuJwrHp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf model*\n",
        "from tensorflow.python.saved_model import builder as saved_model_builder\n",
        "from tensorflow.python.saved_model import signature_constants\n",
        "from tensorflow.python.saved_model import signature_def_utils\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "from tensorflow.python.saved_model import utils as saved_model_utils\n",
        "\n",
        "# Copied a method of https://github.com/GoogleCloudPlatform/cloudml-samples/blob/bf0680726/flowers/trainer/model.py#L52\n",
        "def build_signature(inputs, outputs):\n",
        "  \"\"\"Build the signature.\n",
        "  Not using predic_signature_def in saved_model because it is replacing the\n",
        "  tensor name, b/35900497.\n",
        "  Args:\n",
        "    inputs: a dictionary of tensor name to tensor\n",
        "    outputs: a dictionary of tensor name to tensor\n",
        "  Returns:\n",
        "    The signature, a SignatureDef proto.\n",
        "  \"\"\"\n",
        "  signature_inputs = {key: saved_model_utils.build_tensor_info(tensor)\n",
        "                      for key, tensor in inputs.items()}\n",
        "  signature_outputs = {key: saved_model_utils.build_tensor_info(tensor)\n",
        "                       for key, tensor in outputs.items()}\n",
        "\n",
        "  signature_def = signature_def_utils.build_signature_def(\n",
        "      signature_inputs, signature_outputs,\n",
        "      signature_constants.PREDICT_METHOD_NAME)\n",
        "\n",
        "  return signature_def\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  input_byte, similarity_op = build_graph(hub_module_url, target_img_path)\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "    # export\n",
        "    output_dir = \"./model\"\n",
        "\n",
        "    keys_placeholder = tf.placeholder(tf.string, shape=[None])\n",
        "    inputs = {\n",
        "      'key': keys_placeholder,\n",
        "      'image_bytes': input_byte\n",
        "    }\n",
        "    keys = tf.identity(keys_placeholder)\n",
        "    outputs = {\n",
        "        'key': keys,\n",
        "        'similarity': similarity_op\n",
        "    }\n",
        "\n",
        "    signature_def = build_signature(inputs=inputs, outputs=outputs)\n",
        "    signature_def_map = {\n",
        "        signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature_def\n",
        "    }\n",
        "    builder = saved_model_builder.SavedModelBuilder(output_dir)\n",
        "    builder.add_meta_graph_and_variables(\n",
        "        sess,\n",
        "        tags=[tag_constants.SERVING],\n",
        "        signature_def_map=signature_def_map)\n",
        "    builder.save()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0kYe7ttTytXx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Google Cloud Authentication\n",
        "Cloud ML Engine에 모델을 등록하기 위해 구글 클라우드 인증을 합니다."
      ]
    },
    {
      "metadata": {
        "id": "Oh-pJUtyy8Dv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flbhFCBCDNWL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create model on Cloud ML Engine\n",
        "\n",
        "저장된 모델파일을 클라우드 머신러닝 엔진에 모델로 등록합니다.\n",
        "\n",
        "아래 입력 폼의 아래 필드는 **나의 계정에 맞게 입력**해야 합니다.\n",
        "\n",
        "* project_id : 나의 Google Cloud Project ID\n",
        "* staging_bucket : 나의 Google Cloud Storage Bucket 주소\n",
        "\n",
        "자세한 내용은 [공식 안내 페이지](https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-training-prediction#set-up-your-gcp-project)를 참고해주세요.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DpkifkrVyORD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "74f3de06-1c96-4650-a857-75368a1ccabd"
      },
      "cell_type": "code",
      "source": [
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'towneers' #@param {type:\"string\"}\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "model_name = 'profile_image_detector' #@param {type:\"string\"}\n",
        "!gcloud ml-engine models create {model_name}\n",
        "\n",
        "version = 'base' #@param {type:\"string\"}\n",
        "staging_bucket = 'gs://towneers-ml'  #@param {type:\"string\"}\n",
        "!gcloud ml-engine versions create {version} --model {model_name} \\\n",
        "  --runtime-version 1.7 --origin ./model --staging-bucket {staging_bucket}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "\u001b[1;33mWARNING:\u001b[0m `--regions` flag will soon be required. Please explicitly specify a region. Using [us-central1] by default.\n",
            "Created ml engine model [projects/towneers/models/profile_image_detector].\n",
            "Creating version (this might take a few minutes)......done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WIL3WebtXYtr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Request to Cloud ML Engine\n",
        "배포된 클라우드 머신러닝 엔진 모델에 이미지 비교 요청을 합니다."
      ]
    },
    {
      "metadata": {
        "id": "MnSU40WQb9ao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Make a instance file to request\n",
        "클라우드 머신러닝 모델의 input 형식에 맞는 요청 파일을 생성합니다."
      ]
    },
    {
      "metadata": {
        "id": "Ceo1i2YH0Elf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2097a0d0-e348-44eb-9d24-cc7f1fcd58d3"
      },
      "cell_type": "code",
      "source": [
        "import base64\n",
        "try:\n",
        "    from StringIO import StringIO\n",
        "except ImportError:\n",
        "    from io import BytesIO as StringIO\n",
        "import json\n",
        "import sys\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "desired_width = 96\n",
        "desired_height = 96\n",
        "\n",
        "# Copied a method of https://github.com/GoogleCloudPlatform/cloudml-samples/blob/bf0680726/flowers/images_to_json.py#L62\n",
        "def make_request_json(input_images, output_json, do_resize):\n",
        "  \"\"\"Produces a JSON request suitable to send to CloudML Prediction API.\n",
        "  Args:\n",
        "    input_images: List of file handles corresponding to images to be encoded.\n",
        "    output_json: File handle of the output json where request will be written.\n",
        "    do_resize: Boolean specifying if script should resize images.\n",
        "  \"\"\"\n",
        "\n",
        "  with open(output_json, 'w') as ff:\n",
        "    for image_handle in input_images:\n",
        "      image = Image.open(image_handle)\n",
        "      resized_handle = StringIO()\n",
        "      is_too_big = ((image.size[0] * image.size[1]) >\n",
        "                    (desired_width * desired_height))\n",
        "      if do_resize and is_too_big:\n",
        "        image = image.resize((desired_width, desired_height), Image.BILINEAR)\n",
        "        image.save(resized_handle, format='JPEG')\n",
        "        contents = resized_handle.getvalue()\n",
        "      else:\n",
        "        contents = tf.gfile.GFile(image_handle, 'rb').read()\n",
        "        \n",
        "      encoded_contents = base64.b64encode(contents)\n",
        "\n",
        "      # key can be any UTF-8 string, since it goes in a HTTP request.\n",
        "      row = json.dumps({'key': image_handle,\n",
        "                        'image_bytes': {'b64': encoded_contents.decode(\"utf-8\")}})\n",
        "\n",
        "      ff.write(row)\n",
        "      ff.write('\\n')\n",
        "\n",
        "image_paths = [target_img_path] + input_img_paths\n",
        "\n",
        "make_request_json(image_paths, 'instances.json', False)\n",
        "\n",
        "!head -n 1 instances.json"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"key\": \"target_img.jpg\", \"image_bytes\": {\"b64\": \"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\"}}\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bZPekn_CZCZh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Online prediction\n",
        "요청 파일을 사용하여 실시간으로 비교 요청하고, 결과를 출력값으로 받아 확인합니다.\n",
        "\n",
        "당근마켓에서는 사용자가 프로필 이미지를 변경할 때 비동기 작업으로 아래와 같이 요청하여 유사도를 측정합니다."
      ]
    },
    {
      "metadata": {
        "id": "a-D5518q4eBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5acada42-a817-4651-af0e-0abadc60df28"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!gcloud ml-engine predict --model {model_name}  \\\n",
        "                   --version {version} \\\n",
        "                   --json-instances instances.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KEY             SIMILARITY\r\n",
            "target_img.jpg  1.0\r\n",
            "input_img0.jpg  0.264985\r\n",
            "input_img1.jpg  0.707859\r\n",
            "input_img2.jpg  0.364175\r\n",
            "input_img3.jpg  0.664559\r\n",
            "CPU times: user 763 ms, sys: 266 ms, total: 1.03 s\n",
            "Wall time: 42 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mRi7dbHYZG4Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Batch prediction\n",
        "비교할 이미지가 많을 경우 요청파일을 클라우드 스토리지에 업로드하고, 비동기 요청 배치작업을 실행합니다. 그리고 결과 데이터는 클라우드 스토리지에 저장됩니다.\n",
        "\n",
        "아래의 필드값은 자신의 계정값으로 설정해야 합니다.\n",
        "\n",
        "* input_gs_storage_path : 요청파일의 클라우드 스토리지 경로\n",
        "* output_gs_storage_path : 결과 데이터가 저장될 클라우드 스토리지 경로\n",
        "\n",
        "당근마켓에서는 기존의 사용자의 모든 이미지를 요청 파일로 변환하여 배치 작업으로 결과를 얻는데 사용했습니다."
      ]
    },
    {
      "metadata": {
        "id": "et8nc8DGTOgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f8c8e44f-e511-4e6e-d2e6-79cdeefda705"
      },
      "cell_type": "code",
      "source": [
        "input_gs_storage_path = 'gs://towneers-ml/profile_img_detector/instances.json' #@param {type:\"string\"}\n",
        "output_gs_storage_path = 'gs://towneers-ml/profile_img_detector/results' #@param {type:\"string\"}\n",
        "\n",
        "# Upload the instances.json file to Cloud Storage\n",
        "!gsutil cp instances.json {input_gs_storage_path}\n",
        "\n",
        "# Request a batch prediction job to Cloud ML Engine\n",
        "!gcloud ml-engine jobs submit prediction profile_image_detect \\\n",
        "    --model {model_name} \\\n",
        "    --input-paths {input_gs_storage_path} \\\n",
        "    --output-path {output_gs_storage_path} \\\n",
        "    --data-format TEXT \\\n",
        "    --region us-central1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://instances.json [Content-Type=application/json]...\n",
            "/ [1 files][ 15.1 KiB/ 15.1 KiB]                                                \n",
            "Operation completed over 1 objects/15.1 KiB.                                     \n",
            "Job [profile_image_detect] submitted successfully.\n",
            "Your job is still active. You may view the status of your job with the command\n",
            "\n",
            "  $ gcloud ml-engine jobs describe profile_image_detect\n",
            "\n",
            "or continue streaming the logs with the command\n",
            "\n",
            "  $ gcloud ml-engine jobs stream-logs profile_image_detect\n",
            "jobId: profile_image_detect\n",
            "state: QUEUED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GK2ZSvOBajRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "81cb3604-a4ec-4d97-f7f2-cb2c1e121664"
      },
      "cell_type": "code",
      "source": [
        "!gcloud ml-engine jobs describe profile_image_detect"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "createTime: '2018-06-18T05:42:15Z'\r\n",
            "endTime: '2018-06-18T05:49:58Z'\r\n",
            "jobId: profile_image_detect\r\n",
            "predictionInput:\r\n",
            "  dataFormat: JSON\r\n",
            "  inputPaths:\r\n",
            "  - gs://towneers-ml/profile_img_detector/instances.json\r\n",
            "  modelName: projects/towneers/models/profile_image_detector\r\n",
            "  outputPath: gs://towneers-ml/profile_img_detector/results\r\n",
            "  region: us-central1\r\n",
            "  runtimeVersion: '1.7'\r\n",
            "predictionOutput:\r\n",
            "  nodeHours: 0.13\r\n",
            "  outputPath: gs://towneers-ml/profile_img_detector/results\r\n",
            "  predictionCount: '5'\r\n",
            "startTime: '2018-06-18T05:42:16Z'\r\n",
            "state: SUCCEEDED\r\n",
            "\r\n",
            "View job in the Cloud Console at:\r\n",
            "https://console.cloud.google.com/ml/jobs/profile_image_detect?project=towneers\r\n",
            "\r\n",
            "View logs at:\r\n",
            "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fprofile_image_detect&project=towneers\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zt5sSumLa5w2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "efc98d3f-6582-4830-edce-007cecd21890"
      },
      "cell_type": "code",
      "source": [
        "!gsutil -m -q cp -r {output_gs_storage_path} ./\n",
        "!ls -lh results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4.0K\r\n",
            "-rw-r--r-- 1 root root   0 Jun 18 05:58 prediction.errors_stats-00000-of-00001\r\n",
            "-rw-r--r-- 1 root root 300 Jun 18 05:58 prediction.results-00000-of-00001\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YpLJD1waeJcL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "03cf1e13-3555-4278-b62f-5678f3d43b5c"
      },
      "cell_type": "code",
      "source": [
        "!cat results/prediction.results-00000-of-00001"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"key\": \"target_img.jpg\", \"similarity\": 0.9999999403953552}\r\n",
            "{\"key\": \"input_img0.jpg\", \"similarity\": 0.2649848461151123}\r\n",
            "{\"key\": \"input_img1.jpg\", \"similarity\": 0.7078585624694824}\r\n",
            "{\"key\": \"input_img2.jpg\", \"similarity\": 0.3641752302646637}\r\n",
            "{\"key\": \"input_img3.jpg\", \"similarity\": 0.6645594239234924}\r\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}